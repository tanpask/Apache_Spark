{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Regression**\n",
    "#### This lab covers a common supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train some models to predict the release year or time period of a song given a set of audio features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The raw data is currently stored in text file.  We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point as a comma-delimited string. Each string starts with the label (a year) followed by numerical audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load testing library\n",
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python2.7/site-packages\")\n",
    "\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "\n",
    "\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile('millionsong.txt', numPartitions)\n",
    "rawData.take(3)\n",
    "samplePoints = rawData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 1\n",
    "#### ** Check the data using `LabeledPoint` **\n",
    "#### In MLlib, labeled training instances are stored using the [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) object.  Write the parsePoint function that takes as input a raw data point, parses it using Python's [unicode.split](https://docs.python.org/2/library/string.html#string.split) method, and returns a `LabeledPoint`.  Use this function to parse samplePoints by applying it to rawData.  Then print out the features and label for the first training point, using the `LabeledPoint.features` and `LabeledPoint.label` attributes. Finally, calculate the number features for this dataset.\n",
    "#### Note that `split()` can be called directly on a `unicode` or `str` object.  For example, `u'split,me'.split(',')` returns `[u'split', u'me']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "# Here is a sample raw data point:\n",
    "# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\n",
    "# In this raw data point, 2001.0 is the label, and the remaining values are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python2.7/site-packages\")\n",
    "\n",
    "import hashlib\n",
    "hashed = lambda x: hashlib.sha1(str(x)).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817] 2001.0\n",
      "12\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "def parsePoint(line):\n",
    "    \"\"\"Converts a comma separated unicode string into a `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        line (unicode): Comma separated unicode string where the first element is the label and the\n",
    "            remaining elements are features.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    feats = line.split(',')\n",
    "    \n",
    "    return LabeledPoint(feats[0], feats[1:])\n",
    "\n",
    "parsedSamplePoints = [parsePoint(line) for line in samplePoints]\n",
    "firstPointFeatures = parsedSamplePoints[0].features\n",
    "firstPointLabel = parsedSamplePoints[0].label\n",
    "print firstPointFeatures, firstPointLabel\n",
    "\n",
    "d = len(firstPointFeatures)\n",
    "print d\n",
    "d2=len(parsedSamplePoints)\n",
    "print d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Using LabeledPoint\n",
    "\n",
    "# TEST \n",
    "from test_helper import Test\n",
    "\n",
    "Test.assertEqualsHashed(d, '7b52009b64fd0a2a49e6d8a939753077792b0554', 'Test 1 success')\n",
    "Test.assertEqualsHashed(firstPointLabel, 'adba49c03474bed805297a6455464fb0604db4d3', 'Test 2 success')\n",
    "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
    "Test.assertEqualsHashed((firstPointFeatures-expectedX0), '363289b928767d708220b62d1313f44725a305e9', \n",
    "                        'Test 3 success')\n",
    "Test.assertEqualsHashed(d2, 'ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4', 'Test 4 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 2\n",
    "#### **Find the range ** and ** Shift labels **\n",
    "#### Now let's examine the labels to find the range of song years.  To do this, first parse each element of the `rawData` RDD, and then find the smallest and largest labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011.0 1922.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "parsedDataInit = rawData.map(parsePoint)\n",
    "onlyLabels = parsedDataInit.map(lambda point: point.label).collect()\n",
    "minYear = min(onlyLabels)\n",
    "maxYear = max(onlyLabels)\n",
    "print maxYear, minYear\n",
    "DataInit=(len(parsedDataInit.take(1)[0].features),hashed(parsedDataInit.map(lambda lp: lp.features[2]).sum()))\n",
    "yearRange = maxYear - minYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Find the range\n",
    "Test.assertEqualsHashed(DataInit, '7eeb056f9e35096daaaa6a8b814296693435242f', 'unexpected number of features in sample point')\n",
    "Test.assertEqualsHashed(yearRange, '7ba8ed7dbc6518d461534ab671348bcbbeff6b42', 'incorrect label for firstPointLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we just saw, the labels are years in the 1900s and 2000s.  In learning problems, it is often natural to shift labels such that they start from zero.  Starting with `parsedDataInit`, create a new RDD consisting of `LabeledPoint` objects in which the labels are shifted such that smallest label equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.regression.LabeledPoint'>\n",
      "\n",
      "[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817])]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "parsedData = parsedDataInit.map(lambda lp: LabeledPoint(lp.label - minYear, lp.features))\n",
    "\n",
    "# Should be a LabeledPoint\n",
    "print type(parsedData.take(1)[0])\n",
    "# View the first point\n",
    "print '\\n{0}'.format(parsedData.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "89.0\n"
     ]
    }
   ],
   "source": [
    "oldSampleFeatures = parsedDataInit.take(1)[0].features\n",
    "newSampleFeatures = parsedData.take(1)[0].features\n",
    "DiffSampleFeatures=oldSampleFeatures-newSampleFeatures\n",
    "\n",
    "minYearNew = parsedData.map(lambda lp: lp.label).min()\n",
    "maxYearNew = parsedData.map(lambda lp: lp.label).max()\n",
    "yearNewRange=maxYearNew-minYearNew\n",
    "\n",
    "sumFeatTwo = parsedData.map(lambda lp: lp.features[2]).sum()\n",
    "print DiffSampleFeatures\n",
    "print yearNewRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Shift labels\n",
    "Test.assertEqualsHashed(DiffSampleFeatures, 'ec2e1dc7b5acfefe5ddd5683a5770daa571fa7af', 'new features do not match old features')\n",
    "Test.assertEqualsHashed(yearNewRange, '7ba8ed7dbc6518d461534ab671348bcbbeff6b42', 'incorrect label for firstPointLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 3\n",
    "#### **Training, validation, and test sets **\n",
    "#### We're almost done parsing our first dataset, and our final task involves split it into training, validation and test sets. Use the [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) with the specified weights and seed to create RDDs storing each of these datasets. Next, cache each of these RDDs, as we will be accessing them multiple times in the remainder of this lab. Finally, compute the size of each dataset and verify that the sum of their sizes equals the 6724."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5371 682 671 6724\n",
      "6724\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights, seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTestData.cache()\n",
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "nTest = parsedTestData.count()\n",
    "\n",
    "parsedDataAll=[parsedTrainData.getNumPartitions(),parsedValData.getNumPartitions(),parsedTestData.getNumPartitions()]\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2526.8775765567962, 297.34039429812117, 184.23587665435255]\n",
      "6724\n"
     ]
    }
   ],
   "source": [
    "sumFeatTwo = (parsedTrainData\n",
    "              .map(lambda lp: lp.features[2])\n",
    "              .sum())\n",
    "sumFeatThree = (parsedValData\n",
    "                .map(lambda lp: lp.features[3])\n",
    "                .reduce(lambda x, y: x + y))\n",
    "sumFeatFour = (parsedTestData\n",
    "               .map(lambda lp: lp.features[4])\n",
    "               .reduce(lambda x, y: x + y))\n",
    "listSums=[sumFeatTwo, sumFeatThree, sumFeatFour]\n",
    "sumWhole=nTrain + nVal + nTest\n",
    "print listSums\n",
    "print sumWhole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(sumWhole, '2cfc84ed2f2c864291ee146be109eb4a10e32a35', 'unexpected Train, Val, Test data set size')\n",
    "Test.assertEqualsHashed(listSums, '6cbf9887b7256a2d4bd71f4f203ed18f2662ecd4', 'parsed Train, Val, Test data has unexpected values')\n",
    "Test.assertEqualsHashed(parsedDataAll, '0019ff765b7fae3ae321cef02d908d445ac66006', 'parsedDatas have wrong number of partitions')\n",
    "Test.assertEqualsHashed(len(parsedTrainData.take(1)[0].features), '7b52009b64fd0a2a49e6d8a939753077792b0554', \n",
    "                        'parsedTrainData havs wrong number of features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready to traine the Linear Regression model\n",
    "### EXERCISE 4\n",
    "#### **MLlib's [LinearRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD)**\n",
    "####First use LinearRegressionWithSGD to train a model with L2 regularization and with an intercept.  This method returns a [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel).  Next, use the model's [weights](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.weights) and [intercept](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.intercept) attributes to print out the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "# Values to use when training the linear regression model\n",
    "numIters = 500  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.9789216525,13.923582484,0.781551054803,6.09257051566,3.91814791179,-2.30347707767,10.3002026917,3.04565129011,7.23175674717,4.65796458476,7.98875075855,3.1782463856] 13.3763009811\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData,iterations=numIters,step=alpha,miniBatchFraction=miniBatchFrac,\n",
    "                                           regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR1 = firstModel.weights\n",
    "interceptLR1 = firstModel.intercept\n",
    "print weightsLR1, interceptLR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST LinearRegressionWithSGD\n",
    "expectedIntercept = 13.3335907631\n",
    "expectedWeights = [16.682292427, 14.7439059559, -0.0935105608897, 6.22080088829, 4.01454261926, -3.30214858535,\n",
    "                   11.0403027232, 2.67190962854, 7.18925791279, 4.46093254586, 8.14950409475, 2.75135810882]\n",
    "Test.assertEqualsHashed(abs(interceptLR1-expectedIntercept)<1, '88b33e4e12f75ac8bf792aebde41f1a090f3a612', \n",
    "                        'incorrect value for interceptLR1')\n",
    "Test.assertEqualsHashed(abs(weightsLR1[0]-expectedWeights[0])<1, '88b33e4e12f75ac8bf792aebde41f1a090f3a612', \n",
    "                        'incorrect value for weightsLR1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now use the [LinearRegressionModel.predict()](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.predict) method to make a prediction on a sample point.  Pass the `features` from a `LabeledPoint` into the `predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.5823796609\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "samplePoint = parsedTrainData.take(1)[0]\n",
    "samplePrediction = firstModel.predict(samplePoint.features)\n",
    "print samplePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Predict\n",
    "Test.assertEqualsHashed(abs(samplePrediction - 56.8013380112)<1, '88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'incorrect value for samplePrediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We naturally would like to see how well this performs.  We will use root mean squared error ([RMSE](http://en.wikipedia.org/wiki/Root-mean-square_deviation)) for evaluation purposes.  Implement a function to compute RMSE given an RDD of (label, prediction) tuples, and test out this function on an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29099444874\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def squaredError(label, prediction):\n",
    "    \"\"\"Calculates the the squared error for a single prediction.\n",
    "    Args:\n",
    "        label (float): The correct value for this observation.\n",
    "        prediction (float): The predicted value for this observation.\n",
    "    Returns:\n",
    "        float: The difference between the `label` and `prediction` squared.\n",
    "    \"\"\"\n",
    "    return (label - prediction) ** 2\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
    "    Args:\n",
    "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    return np.sqrt(labelsAndPreds\n",
    "                   .map(lambda (label, prediction): squaredError(label, prediction))\n",
    "                   .mean())\n",
    "\n",
    "labelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\n",
    "# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\n",
    "exampleRMSE = calcRMSE(labelsAndPreds)\n",
    "print exampleRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Root mean squared error\n",
    "Test.assertEqualsHashed(squaredError(3, 1), '1b6453892473a467d07372d45eb05abc2031647a', 'incorrect definition of squaredError')\n",
    "Test.assertEqualsHashed(exampleRMSE, '4b322e37f07576b9230316f90b84285b5d096941', 'incorrect value for exampleRMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next evaluate the accuracy of this model on the validation set.  Use the `predict()` method to create a `labelsAndPreds` RDD, and then use the `calcRMSE()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: LR1 = 19.87307010662\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "labelsAndPreds = parsedValData.map(lambda lp: (lp.label, firstModel.predict(lp.features)))\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print ('Validation RMSE: LR1 = {0:.11f}').format(rmseValLR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're already outperforming the baseline on the validation set by almost 2 years on average, but let's see if we can do better. Perform grid search to find a good regularization parameter.  Try `regParam` values `1e-10`, `1e-5`, and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4831362704\n",
      "17.4834818658\n",
      "23.8000672935\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "bestRMSE = rmseValLR1\n",
    "bestRegParam = reg\n",
    "bestModel = firstModel\n",
    "\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "for reg in [1e-10, 1e-5, 1]:\n",
    "    model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                          miniBatchFrac, regParam=reg,\n",
    "                                          regType='l2', intercept=True)\n",
    "    labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "    rmseValGrid = calcRMSE(labelsAndPreds)\n",
    "    print rmseValGrid\n",
    "\n",
    "    if rmseValGrid < bestRMSE:\n",
    "        bestRMSE = rmseValGrid\n",
    "        bestRegParam = reg\n",
    "        bestModel = model\n",
    "rmseValLRGrid = bestRMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 18 success\n"
     ]
    }
   ],
   "source": [
    "# TEST Grid search\n",
    "Test.assertEqualsHashed((abs(rmseValLRGrid-17.017170071631259)<1,abs(rmseValLR1-19.691247341628721)<1), '6d968538694d0ff0b4e434242f8929869ce29fba', \n",
    "                        'incorrect values for rmseValLRGrid and rmseValLR1', 'Test 18 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sometimes enough predict the time period. Let's traine some enouther model for period time prediction.\n",
    "\n",
    "### EVERCISE 5\n",
    "#### **MLlib's [DecisionTree](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=pyspark.mllib.tree#pyspark.mllib.tree.DecisionTree)** and **[RandomForest](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=pyspark.mllib.tree#pyspark.mllib.tree.RandomForest)** Classifier\n",
    "#### First we need replace year lable for time period label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def period_labels(in_line):\n",
    "    if minYear <= in_line.label < 1940.0:\n",
    "        in_line.label = 0.0\n",
    "    elif 1940.0 <= in_line.label < 1960.0:\n",
    "        in_line.label = 1.0\n",
    "    elif 1960.0 <= in_line.label < 1980.0:\n",
    "        in_line.label = 2.0\n",
    "    elif 1980.0 <= in_line.label < 2000.0:\n",
    "        in_line.label = 3.0\n",
    "    elif 2000.0 <= in_line.label <= maxYear:\n",
    "        in_line.label = 4.0\n",
    "    return in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next create a new dataset with **period_labels()** function. Try to get it from rawData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "parsedData2 = rawData.map(parsePoint).map(period_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 19 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(parsedData2.map(lambda lp: lp.label).sum(), '0a64c49801579d52880487ca045606a2a37374a8', \n",
    "                        'Wrong period labels in Data', 'Test 19 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And split randomly  **parsedData2** to **parsedTrainData2** and **parsedTestData2** with **weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = [.7, .3]\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "seed = 42\n",
    "(parsedTrainData2, parsedTestData2) = parsedData2.randomSplit(weights, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 20 success\n",
      "1 test passed. Test 21 success\n",
      "1 test passed. Test 22 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(parsedTrainData2.map(lambda lp: lp.label).sum(), '321d01504f5827edab56fde6fb493762f5d37521', \n",
    "                        'Incorect splitting', 'Test 20 success')\n",
    "Test.assertEqualsHashed(parsedTestData2.map(lambda lp: lp.label).sum(), '3ceee74eedb864ff868f9f0e67464a8f7a3abd05', \n",
    "                        'Incorect splitting', 'Test 21 success')\n",
    "Test.assertEqualsHashed(np.allclose(parsedData2.map(lambda lp: lp.label).sum(), \n",
    "                                    (parsedTrainData2.map(lambda lp: lp.label).sum()+parsedTestData2.map(lambda lp: lp.label).sum())), \n",
    "                                     '88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Incorect splitting', 'Test 22 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Train DecisionTree model and predict it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "model = DecisionTree.trainClassifier(parsedTrainData2, numClasses=6, categoricalFeaturesInfo={},\n",
    "                                         impurity='gini', maxDepth=20, maxBins=20)\n",
    "    \n",
    "predictions = model.predict(parsedTestData2.map(lambda x: x.features))\n",
    "labelsAndPredictions_DecisionTree = parsedTestData2.map(lambda lp: lp.label).zip(predictions)\n",
    "# Calculate accuracy our test prediction for model DecisionTree\n",
    "test_acc_DecisionTree = (labelsAndPredictions_DecisionTree.filter(lambda (v, p): v == p).count() / float(parsedTestData2.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 23 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(test_acc_DecisionTree>=0.41,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong DecisionTree model prediction', \n",
    "                        'Test 23 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Train RandomForest model and predict it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "\n",
    "model = RandomForest.trainClassifier(parsedTrainData2, numClasses=6, categoricalFeaturesInfo={},\n",
    "                                     numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)\n",
    "\n",
    "predictions = model.predict(parsedTestData2.map(lambda x: x.features))\n",
    "# Calculate accuracy our test prediction for model DecisionTree\n",
    "labelsAndPredictions_RandomForest = parsedTestData2.map(lambda lp: lp.label).zip(predictions)\n",
    "test_acc_RandomForest = labelsAndPredictions_RandomForest.filter(lambda (v, p): v == p).count() / float(parsedTestData2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 24 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(test_acc_RandomForest>=0.4,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong RandomForest model prediction', \n",
    "                        'Test 24 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.427078148333\n",
      "Test Accuracy = 0.427575908412\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy = ' + str(test_acc_DecisionTree))\n",
    "print('Test Accuracy = ' + str(test_acc_RandomForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVERCISE 6\n",
    "#### **MLlib's [LogisticRegressionWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=logisticregressionwithsgd#pyspark.mllib.classification.LogisticRegressionWithSGD)** and **[SVMWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=svmwithsgd#pyspark.mllib.classification.SVMWithSGD)**\n",
    "#### Create **period_binary()** function to get two labels for each millennium (1.0 for current millennium, and 0.0 - for previous). Get **parsedData3**, **parsedTrainData3**, **parsedTestData3** with this function and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "def period_binary(in_line):\n",
    "    if in_line.label < 2000.0:\n",
    "        in_line.label = 0.0\n",
    "    elif 2000.0<=in_line.label:\n",
    "        in_line.label = 1.0\n",
    "    return in_line\n",
    "\n",
    "parsedData3 = rawData.map(parsePoint).map(period_binary)\n",
    "(parsedTrainData3, parsedTestData3) = parsedData3.randomSplit(weights, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 25 success\n",
      "1 test passed. Test 26 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(parsedData3.map(lambda lp: lp.label).sum(),'2f96c1c8410ef66dfd763f0810550308d2879777', \n",
    "                        'Wrong period labels in Data', 'Test 25 success')\n",
    "Test.assertEqualsHashed((parsedTrainData3.map(lambda lp: lp.label).sum()+parsedTestData3.map(lambda lp: lp.label).sum()),\n",
    "                        '2f96c1c8410ef66dfd763f0810550308d2879777', 'Incorect splitting', 'Test 26 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traine and predict LogisticRegressionWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "model = LogisticRegressionWithSGD.train(parsedTrainData3,iterations=10)\n",
    "\n",
    "predictions = model.predict(parsedTestData3.map(lambda x: x.features))\n",
    "\n",
    "labelsAndPreds_LogisticRegression = parsedTestData3. map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 27 success\n"
     ]
    }
   ],
   "source": [
    "a = labelsAndPreds_LogisticRegression.filter(lambda (v, p): v == p).count() / float(parsedTestData3.count())\n",
    "Test.assertEqualsHashed(a>=0.82,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong LogisticRegression model prediction', \n",
    "                        'Test 27 success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate test error (opposite to training accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.158785465406\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "trainErr_LogisticRegression = labelsAndPreds_LogisticRegression.filter(lambda (v, p): v != p).count() / float(parsedTestData3.count())\n",
    "print(\"Test Error = \" + str(trainErr_LogisticRegression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traine and predict SVMWithSGD. Then calculate test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "\n",
    "model = SVMWithSGD.train(parsedTrainData3,iterations=10)\n",
    "predictions = model.predict(parsedTestData3.map(lambda x: x.features))\n",
    "\n",
    "labelsAndPreds_SVMWithSGD =  parsedTestData3. map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 28 success\n"
     ]
    }
   ],
   "source": [
    "a = labelsAndPreds_SVMWithSGD.filter(lambda (v, p): v == p).count() / float(parsedTestData3.count())\n",
    "Test.assertEqualsHashed(a>=0.82,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong SVMWithSGD model prediction', \n",
    "                        'Test 28 success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.158785465406\n",
      "Test Error = 0.158785465406\n"
     ]
    }
   ],
   "source": [
    "trainErr_SVMWithSGD = labelsAndPreds_SVMWithSGD.filter(lambda (v, p): v != p).count() / float(parsedTestData3.count())\n",
    "\n",
    "# Comparison test error LogisticRegressionWithSGD and SVMWithSGD\n",
    "print(\"Test Error = \" + str(trainErr_LogisticRegression))\n",
    "print(\"Test Error = \" + str(trainErr_SVMWithSGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed. Test 29 success\n",
      "1 test passed. Test 30 success\n"
     ]
    }
   ],
   "source": [
    "Test.assertEqualsHashed(trainErr_LogisticRegression<=0.18,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong LogisticRegression err calculation', \n",
    "                        'Test 29 success')\n",
    "Test.assertEqualsHashed(trainErr_SVMWithSGD<=0.18,'88b33e4e12f75ac8bf792aebde41f1a090f3a612', 'Wrong SVMWithSGD err calculation', \n",
    "                        'Test 30 success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
